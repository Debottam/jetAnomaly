{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import h5py\n",
    "import pickle\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "#import deepdish.io as io\n",
    "#import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from keras.models import Model,Sequential\n",
    "#from keras.layers import Input, Dense, Dropout, Layer\n",
    "#from keras.utils import plot_model\n",
    "#from keras.models import load_model\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "import random\n",
    "from pca_plotter import PCAPlotter\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tripletnet(keras.Model):\n",
    "    def __init__(self, embeddingnet):\n",
    "        super(Tripletnet, self).__init__()\n",
    "        self.embeddingnet = embeddingnet\n",
    "\n",
    "    def call(self, x, y, z):\n",
    "        #print(\"x: \",x)\n",
    "        #print(\"y: \",y)\n",
    "        #print(\"z: \",z)\n",
    "        latent_x,mean_x,logvar_x = self.embeddingnet(x)\n",
    "        latent_y,mean_y,logvar_y = self.embeddingnet(y)\n",
    "        latent_z,mean_z,logvar_z = self.embeddingnet(z)\n",
    "        dist_a = tf.reduce_mean(tf.square(mean_x - mean_y), axis=1)\n",
    "        dist_b = tf.reduce_mean(tf.square(mean_x - mean_z), axis=1)\n",
    "        return latent_x,mean_x,logvar_x,\\\n",
    "            latent_y,mean_y,logvar_y,\\\n",
    "            latent_z,mean_z,logvar_z,\\\n",
    "            dist_a, dist_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    mu, sigma = args\n",
    "    batch     = tf.shape(mu)[0]\n",
    "    dim       = tf.shape(mu)[1]\n",
    "    eps       = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return mu + tf.exp(sigma / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 80\n",
    "encoding_dim = 10\n",
    "inputs = keras.Input((None, input_dim))\n",
    "\n",
    "class _Encoder(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(_Encoder, self).__init__(**kwargs)\n",
    "        #self.input_dim = input_dim\n",
    "        #self.encoding_dim = encoding_dim\n",
    "        #self.Input = keras.Input((None, self.input_dim))\n",
    "        self.layer_1 = layers.Dense(256, activation=\"relu\")\n",
    "        self.layer_2 = layers.Dense(128, activation=\"relu\")\n",
    "        self.layer_3 = layers.Dense(64, activation=\"relu\")\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        x = self.layer_1(inputs)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        self.mean = layers.Dense(encoding_dim, name=\"z_mean\")(x)\n",
    "        self.log_var = layers.Dense(encoding_dim, name=\"z_log_var\")(x)\n",
    "        self.z = layers.Lambda(sampling, output_shape=(encoding_dim,), name='z')([self.mean, self.log_var])\n",
    "        return self.z, self.mean, self.log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Decoder(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(_Decoder, self).__init__()\n",
    "        #self.encoding_dim = encoding_dim\n",
    "        #self.Input = keras.Input(shape=(self.encoding_dim,), name='z_sampling')\n",
    "        #self.layer_1 = layers.Dense(64, activation=\"relu\")\n",
    "        self.layer_1 = layers.Dense(128, activation=\"relu\")\n",
    "        self.layer_2 = layers.Dense(256, activation=\"relu\")\n",
    "        self.layer_3 = layers.Dense(80, activation=\"sigmoid\")\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x = self.layer_1(inputs)\n",
    "        x = self.layer_2(x)\n",
    "        output = self.layer_3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_reconstruction_loss(x, recon_x, mu, log_var):\n",
    "    reco_loss = tf.reduce_sum(tf.pow(x - recon_x,2))/80\n",
    "    kl_loss = 1 + log_var - tf.square(mu) - tf.exp(log_var)\n",
    "    kl_loss = tf.reduce_sum(kl_loss, axis= -1)\n",
    "    kl_loss *= -0.5\n",
    "    return tf.reduce_mean(reco_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(batch_size=256):\n",
    "    x_anchors = np.zeros((batch_size, 80))\n",
    "    x_positives = np.zeros((batch_size, 80))\n",
    "    x_negatives = np.zeros((batch_size, 80))\n",
    "    \n",
    "    for i in range(0,batch_size):\n",
    "        # We need to find an anchor, a positive example and a negative example\n",
    "        random_index = random.choice(bkg_index)\n",
    "        x_anchor = x_train[random_index]\n",
    "        y = y_train[random_index]\n",
    "        \n",
    "        indices_for_pos = np.squeeze(np.where(y_train == y))\n",
    "        indices_for_neg = np.squeeze(np.where(y_train != y))\n",
    "        \n",
    "        x_positive = x_train[indices_for_pos[random.randint(0, len(indices_for_pos) - 1)]]\n",
    "        x_negative = x_train[indices_for_neg[random.randint(0, len(indices_for_neg) - 1)]]\n",
    "        \n",
    "        x_anchors[i] = x_anchor\n",
    "        x_positives[i] = x_positive\n",
    "        x_negatives[i] = x_negative\n",
    "        \n",
    "    return [x_anchors, x_positives, x_negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qcd_train:  (200000, 80)\n",
      "zboson_pt_scaled.shape:  (97579, 80)\n",
      "ttbar_pt_scaled:  (320124, 80)\n"
     ]
    }
   ],
   "source": [
    "# Data loading part\n",
    "# Loading QCD sample to use jet_pT for pT scaling\n",
    "fqcd=h5py.File('/home/zp/gupta/jetAnomaly/utils/qcd_pt_scaled.h5','r')\n",
    "qcd_train_bkg = fqcd['table']\n",
    "qcd_train_bkg=qcd_train_bkg[:,:80]\n",
    "qcd_train = qcd_train_bkg[0:200000]\n",
    "print (\"qcd_train: \",qcd_train.shape)\n",
    "\n",
    "# Loading zboson sample to use jet_pT for pT scaling\n",
    "fzboson=h5py.File('/lcg/storage13/atlas/gupta/stealth_boson/Zp2200_S80A15_pt_scaled.h5','r')\n",
    "zboson_pt_scaled = fzboson['table']\n",
    "zboson_pt_scaled = zboson_pt_scaled[:,:80]\n",
    "print (\"zboson_pt_scaled.shape: \",zboson_pt_scaled.shape)\n",
    "\n",
    "# Loading ttbar sample to use jet_pT for pT scaling\n",
    "fttbar=h5py.File('/home/zp/gupta/jetAnomaly/utils/ttbar_pt_scaled.h5','r')\n",
    "ttbar_pt_scaled = fttbar['table']\n",
    "ttbar_pt_scaled = ttbar_pt_scaled[:,:80]\n",
    "print (\"ttbar_pt_scaled: \",ttbar_pt_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (297000, 80)\n",
      "y_train:  (297000,)\n"
     ]
    }
   ],
   "source": [
    "# mixing qcd and z_boson for training\n",
    "qcd_zboson_mixed = np.concatenate((qcd_train, zboson_pt_scaled), axis=0)\n",
    "y_qcd_zboson = np.concatenate((np.zeros(len(qcd_train)), np.ones(len(zboson_pt_scaled))), axis=0)\n",
    "rng = check_random_state(1)\n",
    "indices = rng.permutation(len(qcd_zboson_mixed))\n",
    "x_train = np.array([qcd_zboson_mixed[j] for j in indices[:297000]])\n",
    "y_train = np.array([y_qcd_zboson[j] for j in indices[:297000]])\n",
    "print(\"x_train: \",x_train.shape)\n",
    "print(\"y_train: \",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test:  (150000, 80)\n",
      "y_test:  (150000,)\n"
     ]
    }
   ],
   "source": [
    "# mixing qcd and tt_bar for test\n",
    "qcd_test_bkg = qcd_train_bkg[200000:300000]\n",
    "ttbar_test = ttbar_pt_scaled[0:50000]\n",
    "qcd_ttbar_mixed = np.concatenate((qcd_test_bkg, ttbar_test), axis=0)\n",
    "y_qcd_ttbar = np.concatenate((np.zeros(len(qcd_test_bkg)), np.ones(len(ttbar_test))), axis=0)\n",
    "rng = check_random_state(1)\n",
    "indices_1 = rng.permutation(len(qcd_ttbar_mixed))\n",
    "x_test = qcd_ttbar_mixed[indices_1]\n",
    "y_test = y_qcd_ttbar[indices_1]\n",
    "print(\"x_test: \",x_test.shape)\n",
    "print(\"y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling datasets\n",
    "scaler = RobustScaler().fit(x_train)\n",
    "x_train_scaled=scaler.transform(x_train)\n",
    "x_test_scaled=scaler.transform(x_test)\n",
    "bkg_index = np.where(y_train == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_scaled,y_train))\n",
    "train_dataset = train_dataset.batch(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "step:  1\n",
      "WARNING:tensorflow:Layer tripletnet_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer private__encoder_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "BatchLoss:  tf.Tensor(0.4418135, shape=(), dtype=float32)\n",
      "step:  2\n",
      "BatchLoss:  tf.Tensor(0.42858505, shape=(), dtype=float32)\n",
      "step:  3\n",
      "BatchLoss:  tf.Tensor(0.4173799, shape=(), dtype=float32)\n",
      "step:  4\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "epoch_losses = []\n",
    "num_epochs = 1\n",
    "encoder= _Encoder()\n",
    "decoder = _Decoder()\n",
    "tnet = Tripletnet(encoder)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "for epoch in range (num_epochs):\n",
    "    batch_losses = []\n",
    "    step = 0\n",
    "    print(\"epoch: \", epoch)\n",
    "    for x,y in train_dataset:\n",
    "        step = step+1\n",
    "        print(\"step: \",step)\n",
    "        batch_size=x.shape[0]\n",
    "        anchor,positive,negative = create_batch(batch_size)\n",
    "        #encoder= _Encoder()\n",
    "        #tnet = Tripletnet(encoder)\n",
    "        batch_loss=0\n",
    "        with tf.GradientTape() as tape:\n",
    "            for idx in range (batch_size):\n",
    "                #print(\"idx: \", idx)\n",
    "            #with tf.GradientTape() as tape:\n",
    "                latent_ach,mean_ach,logvar_ach,\\\n",
    "                latent_p,mean_p,logvar_p,\\\n",
    "                latent_n,mean_n,logvar_n,dp,dn = tnet(\\\n",
    "                                                  anchor[idx,:].reshape((1,80)),\\\n",
    "                                                   positive[idx,:].reshape((1,80)),\\\n",
    "                                                   negative[idx,:].reshape((1,80)))\n",
    "            #get reconstructed images\n",
    "                reconstructed_ach = decoder(latent_ach)\n",
    "                reconstructed_p = decoder(latent_p)\n",
    "            #reconstructed_n = decoder(latent_n)\n",
    "                loss_vae = kl_reconstruction_loss(anchor[idx],reconstructed_ach,mean_ach,logvar_ach)\n",
    "                loss_vae += kl_reconstruction_loss(positive[idx],reconstructed_p,mean_p,logvar_p)\n",
    "            #loss_vae += kl_reconstruction_loss(negative,reconstructed_n,mean_n,logvar_n)\n",
    "                loss_vae = loss_vae/2\n",
    "                loss_triplet = float(tf.maximum(dp - dn + alpha, 0.))\n",
    "                loss = loss_vae + loss_triplet\n",
    "            #print(\"Loss: \", loss)\n",
    "                batch_loss=batch_loss+loss\n",
    "                #print(\"Loss: \", batch_loss)\n",
    "            batch_loss=batch_loss/batch_size\n",
    "            print(\"BatchLoss: \", batch_loss)\n",
    "            total_trainable_variables = encoder.trainable_variables+decoder.trainable_variables\n",
    "        #with tf.GradientTape() as tape:\n",
    "        grads = tape.gradient(batch_loss,total_trainable_variables)\n",
    "        #print(\"grads:\",grads)\n",
    "        batch_losses.append(batch_loss)\n",
    "        optimizer.apply_gradients(zip(grads,total_trainable_variables))\n",
    "    epoch_losses.append(np.mean(batch_losses))    \n",
    "    print(\"epoch: \",epoch)\n",
    "    print(\"loss: \",epoch_losses[epoch])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = _Encoder()\n",
    "z, mean, var = encoder(tf.random.uniform([1,80]))\n",
    "#decoder.summary()\n",
    "#encoder.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.trainable_variables+encoder.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet = Tripletnet(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tf.Tensor(\n",
      "[[0.47968566 0.8685161  0.20535028 0.6449919  0.3137709  0.0355078\n",
      "  0.81877327 0.32247186 0.16846299 0.37724316 0.98070943 0.8950027\n",
      "  0.97280204 0.89592063 0.619872   0.19825506 0.8513619  0.2199322\n",
      "  0.6050823  0.03683317 0.65182185 0.21700573 0.13112211 0.5535033\n",
      "  0.9302949  0.61054885 0.8319149  0.6418209  0.73408437 0.7017555\n",
      "  0.80665326 0.76897967 0.19125712 0.8082844  0.2850275  0.39690197\n",
      "  0.8053887  0.9291786  0.66929877 0.6776484  0.495692   0.3982854\n",
      "  0.6780145  0.44304347 0.49872398 0.2152468  0.91120946 0.73842585\n",
      "  0.8819351  0.00273609 0.08374417 0.47193253 0.5077473  0.09605086\n",
      "  0.39067817 0.8858328  0.1313597  0.51842296 0.6573427  0.17632055\n",
      "  0.4092101  0.09171724 0.6594218  0.7447177  0.89163053 0.82151496\n",
      "  0.25391662 0.9527339  0.49785638 0.8831736  0.2391988  0.5145031\n",
      "  0.7945448  0.11219442 0.7497206  0.661505   0.41400743 0.81654084\n",
      "  0.9121282  0.26904356]], shape=(1, 80), dtype=float32)\n",
      "y:  tf.Tensor(\n",
      "[[0.48911035 0.42051756 0.05318868 0.43036222 0.40055466 0.79635704\n",
      "  0.7536261  0.27262235 0.24809194 0.99638057 0.1336168  0.08954239\n",
      "  0.44570947 0.4847226  0.25685346 0.6683768  0.27083552 0.36925888\n",
      "  0.3306241  0.1404059  0.6399249  0.5554681  0.9418223  0.6404102\n",
      "  0.52692807 0.16259897 0.75844526 0.9012914  0.8530246  0.20557106\n",
      "  0.15425372 0.6994339  0.13438296 0.18675709 0.7813772  0.87472665\n",
      "  0.91681457 0.56116354 0.38621223 0.3844552  0.5168927  0.279253\n",
      "  0.18509173 0.8773813  0.3660456  0.18907821 0.4700575  0.46056426\n",
      "  0.6709459  0.7015697  0.7216439  0.07553744 0.945258   0.78877664\n",
      "  0.3350383  0.13816226 0.5012002  0.17346454 0.9081011  0.64500463\n",
      "  0.6260818  0.7679697  0.96298206 0.5208185  0.48791027 0.09483182\n",
      "  0.4558277  0.63709927 0.7753277  0.5521939  0.16457212 0.9882473\n",
      "  0.9918909  0.7499808  0.7841507  0.47380257 0.905529   0.01196015\n",
      "  0.3861227  0.43843055]], shape=(1, 80), dtype=float32)\n",
      "z:  tf.Tensor(\n",
      "[[0.30586863 0.32274258 0.9546155  0.15149403 0.4285643  0.50716484\n",
      "  0.43985355 0.10599756 0.98257136 0.31828928 0.4845873  0.16796768\n",
      "  0.14582479 0.8401865  0.8804785  0.11612189 0.27371013 0.5493566\n",
      "  0.42324984 0.07345426 0.35968816 0.35719824 0.3302673  0.8648\n",
      "  0.25999844 0.61898375 0.5687778  0.9990436  0.9690136  0.24623477\n",
      "  0.58058023 0.0058198  0.28958547 0.15341473 0.25535262 0.43326294\n",
      "  0.45528114 0.4989164  0.37003052 0.7288176  0.82222676 0.689342\n",
      "  0.901664   0.75253904 0.48249793 0.13678014 0.3502128  0.6523073\n",
      "  0.852844   0.4352864  0.76602757 0.671348   0.18772769 0.60145736\n",
      "  0.8522935  0.5444932  0.13268912 0.6615523  0.15400767 0.62647736\n",
      "  0.3515563  0.5083481  0.7232406  0.09535801 0.42350936 0.6938975\n",
      "  0.83887386 0.48020697 0.7215738  0.5460278  0.91456664 0.60563886\n",
      "  0.4404875  0.8502344  0.05015159 0.70604086 0.6638465  0.6795844\n",
      "  0.8761903  0.5706451 ]], shape=(1, 80), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "_,_,_,_,_,_,_,_,_,dp,dn = tnet(tf.random.uniform([1,80]),tf.random.uniform([1,80]),tf.random.uniform([1,80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.10372391], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#float(dn)\n",
    "dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_img_file = './model_1.png'\n",
    "tf.keras.utils.plot_model(encoder,to_file=dot_img_file, show_shapes=True, show_layer_names= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envTf2",
   "language": "python",
   "name": "envtf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
